{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Grabs dangerous information on road closures through NewsAPI.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Grabs dangerous information on road closures through NewsAPI.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import InfoAPI\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "key = InfoAPI.NewsAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class News:\n",
    "    \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def main(self, city_name='Austin'):\n",
    "        \"\"\"Engine to gather all texts from different news and blogs for road closure.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        city_name : string\n",
    "            Contains the city that you are in; if none given, default is Austin.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        texts : list\n",
    "            Contains a list of all texts that have road closure in it.\n",
    "\n",
    "        \"\"\"\n",
    "        date = datetime.now()\n",
    "        date_format = f\"{date.year}-{date.month}-{date.day}\"\n",
    "\n",
    "        BASE_URL = \"https://newsapi.org/v2/everything/\"\n",
    "\n",
    "        params = {\n",
    "            'q': city_name,\n",
    "            'apiKey': self.key.API_KEY,\n",
    "            'from': date_format,\n",
    "            'to': date_format,\n",
    "        }\n",
    "\n",
    "        response = requests.get(BASE_URL, params)\n",
    "\n",
    "        articles = response.json()['articles']\n",
    "        urls = get_urls(articles)\n",
    "        texts = use_urls(urls)\n",
    "        return texts\n",
    "\n",
    "    def get_urls(self, articles):\n",
    "        \"\"\"Simply extracts the urls.\n",
    "\n",
    "        Paramters\n",
    "        ---------\n",
    "        articles : list\n",
    "            List of objects that contain an attribute url.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        urls : list\n",
    "            List of extracted urls.\n",
    "\n",
    "        \"\"\"\n",
    "        urls = []\n",
    "        for article in articles:\n",
    "            urls.append(article['url'])\n",
    "        return urls\n",
    "\n",
    "    def use_urls(self, urls, show_errors=False):\n",
    "        \"\"\"Extracts text from each website.\n",
    "\n",
    "        Paramters\n",
    "        ---------\n",
    "        urls : list\n",
    "            A list of urls.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        texts : list\n",
    "            A list of extracted texts from given urls.\n",
    "\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        texts = []\n",
    "        for url in urls:\n",
    "            response = requests.get(url)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                text = get_texts(response)\n",
    "                if len(text) != 0:\n",
    "                    texts.append(text)\n",
    "            else:\n",
    "                if show_errors:\n",
    "                    print(url)\n",
    "                    print(response)\n",
    "                count = count + 1\n",
    "        \n",
    "        if show_errors:\n",
    "            print(f\"There was {count} error(s).\")\n",
    "        return texts\n",
    "\n",
    "    def get_texts(self, response):\n",
    "        \"\"\"Extracts the text from the p element.\n",
    "\n",
    "        Paramters\n",
    "        ---------\n",
    "        response : Response object\n",
    "            e.g. response = requests.get(url)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        texts : list\n",
    "\n",
    "        \"\"\"\n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        paragraphs = soup.find_all('p')\n",
    "        texts = []\n",
    "        for p in paragraphs:\n",
    "            text = p.text\n",
    "            text = process(text)\n",
    "            if text != '':\n",
    "                texts.append(text)\n",
    "\n",
    "        return texts\n",
    "\n",
    "    def process(self, text):\n",
    "        \"\"\"Grabs everything after road closure, inclusively.\n",
    "\n",
    "        Paramters\n",
    "        ---------\n",
    "        text : string\n",
    "            A single string of text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        matches[0] : string\n",
    "            If there is a match, then it will return the string begining with road closure.\n",
    "        '' : string\n",
    "            Returns empty string if there is not a match.\n",
    "\n",
    "        \"\"\"\n",
    "        regex = r\"road .*\"\n",
    "        matches = re.search(regex, text, re.MULTILINE | re.IGNORECASE)\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = News(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.livescience.com/65220-fossils-show-texas-serengeti.html\n",
      "There was 1 error(s).\n"
     ]
    }
   ],
   "source": [
    "text = test.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
